{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation with sklearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick exploratory data analysis\n",
    "The objective of this notebooke is mainly to test the CV functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>218.2</td>\n",
       "      <td>88</td>\n",
       "      <td>37.09</td>\n",
       "      <td>348.5</td>\n",
       "      <td>108</td>\n",
       "      <td>29.62</td>\n",
       "      <td>212.6</td>\n",
       "      <td>118</td>\n",
       "      <td>9.57</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_length      area_code international_plan voice_mail_plan  \\\n",
       "0             107  area_code_415                 no             yes   \n",
       "1             137  area_code_415                 no              no   \n",
       "2              84  area_code_408                yes              no   \n",
       "3              75  area_code_415                yes              no   \n",
       "4             121  area_code_510                 no             yes   \n",
       "\n",
       "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0                     26              161.6              123   \n",
       "1                      0              243.4              114   \n",
       "2                      0              299.4               71   \n",
       "3                      0              166.7              113   \n",
       "4                     24              218.2               88   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             27.47              195.5              103             16.62   \n",
       "1             41.38              121.2              110             10.30   \n",
       "2             50.90               61.9               88              5.26   \n",
       "3             28.34              148.3              122             12.61   \n",
       "4             37.09              348.5              108             29.62   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                254.4                103               11.45   \n",
       "1                162.6                104                7.32   \n",
       "2                196.9                 89                8.86   \n",
       "3                186.9                121                8.41   \n",
       "4                212.6                118                9.57   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                13.7                 3               3.70   \n",
       "1                12.2                 5               3.29   \n",
       "2                 6.6                 7               1.78   \n",
       "3                10.1                 3               2.73   \n",
       "4                 7.5                 7               2.03   \n",
       "\n",
       "   number_customer_service_calls churn  \n",
       "0                              1    no  \n",
       "1                              0    no  \n",
       "2                              2    no  \n",
       "3                              3    no  \n",
       "4                              3    no  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv')   # modify path if needed\n",
    "data = data.drop('state', axis=1)  # drop 'state' for simplicity\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>4250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>100.236235</td>\n",
       "      <td>7.631765</td>\n",
       "      <td>180.259600</td>\n",
       "      <td>99.907294</td>\n",
       "      <td>30.644682</td>\n",
       "      <td>200.173906</td>\n",
       "      <td>100.176471</td>\n",
       "      <td>17.015012</td>\n",
       "      <td>200.527882</td>\n",
       "      <td>99.839529</td>\n",
       "      <td>9.023892</td>\n",
       "      <td>10.256071</td>\n",
       "      <td>4.426353</td>\n",
       "      <td>2.769654</td>\n",
       "      <td>1.559059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.698401</td>\n",
       "      <td>13.439882</td>\n",
       "      <td>54.012373</td>\n",
       "      <td>19.850817</td>\n",
       "      <td>9.182096</td>\n",
       "      <td>50.249518</td>\n",
       "      <td>19.908591</td>\n",
       "      <td>4.271212</td>\n",
       "      <td>50.353548</td>\n",
       "      <td>20.093220</td>\n",
       "      <td>2.265922</td>\n",
       "      <td>2.760102</td>\n",
       "      <td>2.463069</td>\n",
       "      <td>0.745204</td>\n",
       "      <td>1.311434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.325000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>24.365000</td>\n",
       "      <td>165.925000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>14.102500</td>\n",
       "      <td>167.225000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>7.522500</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.450000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30.680000</td>\n",
       "      <td>200.700000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.060000</td>\n",
       "      <td>200.450000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.020000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>216.200000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>233.775000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>19.867500</td>\n",
       "      <td>234.700000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>10.560000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>351.500000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>59.760000</td>\n",
       "      <td>359.300000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>30.540000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>17.770000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account_length  number_vmail_messages  total_day_minutes  \\\n",
       "count     4250.000000            4250.000000        4250.000000   \n",
       "mean       100.236235               7.631765         180.259600   \n",
       "std         39.698401              13.439882          54.012373   \n",
       "min          1.000000               0.000000           0.000000   \n",
       "25%         73.000000               0.000000         143.325000   \n",
       "50%        100.000000               0.000000         180.450000   \n",
       "75%        127.000000              16.000000         216.200000   \n",
       "max        243.000000              52.000000         351.500000   \n",
       "\n",
       "       total_day_calls  total_day_charge  total_eve_minutes  total_eve_calls  \\\n",
       "count      4250.000000       4250.000000        4250.000000      4250.000000   \n",
       "mean         99.907294         30.644682         200.173906       100.176471   \n",
       "std          19.850817          9.182096          50.249518        19.908591   \n",
       "min           0.000000          0.000000           0.000000         0.000000   \n",
       "25%          87.000000         24.365000         165.925000        87.000000   \n",
       "50%         100.000000         30.680000         200.700000       100.000000   \n",
       "75%         113.000000         36.750000         233.775000       114.000000   \n",
       "max         165.000000         59.760000         359.300000       170.000000   \n",
       "\n",
       "       total_eve_charge  total_night_minutes  total_night_calls  \\\n",
       "count       4250.000000          4250.000000        4250.000000   \n",
       "mean          17.015012           200.527882          99.839529   \n",
       "std            4.271212            50.353548          20.093220   \n",
       "min            0.000000             0.000000           0.000000   \n",
       "25%           14.102500           167.225000          86.000000   \n",
       "50%           17.060000           200.450000         100.000000   \n",
       "75%           19.867500           234.700000         113.000000   \n",
       "max           30.540000           395.000000         175.000000   \n",
       "\n",
       "       total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
       "count         4250.000000         4250.000000       4250.000000   \n",
       "mean             9.023892           10.256071          4.426353   \n",
       "std              2.265922            2.760102          2.463069   \n",
       "min              0.000000            0.000000          0.000000   \n",
       "25%              7.522500            8.500000          3.000000   \n",
       "50%              9.020000           10.300000          4.000000   \n",
       "75%             10.560000           12.000000          6.000000   \n",
       "max             17.770000           20.000000         20.000000   \n",
       "\n",
       "       total_intl_charge  number_customer_service_calls  \n",
       "count        4250.000000                    4250.000000  \n",
       "mean            2.769654                       1.559059  \n",
       "std             0.745204                       1.311434  \n",
       "min             0.000000                       0.000000  \n",
       "25%             2.300000                       1.000000  \n",
       "50%             2.780000                       1.000000  \n",
       "75%             3.240000                       2.000000  \n",
       "max             5.400000                       9.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "      <th>area_code_area_code_415</th>\n",
       "      <th>area_code_area_code_510</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>218.2</td>\n",
       "      <td>88</td>\n",
       "      <td>37.09</td>\n",
       "      <td>348.5</td>\n",
       "      <td>108</td>\n",
       "      <td>29.62</td>\n",
       "      <td>212.6</td>\n",
       "      <td>118</td>\n",
       "      <td>9.57</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_length  international_plan  voice_mail_plan  number_vmail_messages  \\\n",
       "0             107                   0                1                     26   \n",
       "1             137                   0                0                      0   \n",
       "2              84                   1                0                      0   \n",
       "3              75                   1                0                      0   \n",
       "4             121                   0                1                     24   \n",
       "\n",
       "   total_day_minutes  total_day_calls  total_day_charge  total_eve_minutes  \\\n",
       "0              161.6              123             27.47              195.5   \n",
       "1              243.4              114             41.38              121.2   \n",
       "2              299.4               71             50.90               61.9   \n",
       "3              166.7              113             28.34              148.3   \n",
       "4              218.2               88             37.09              348.5   \n",
       "\n",
       "   total_eve_calls  total_eve_charge  total_night_minutes  total_night_calls  \\\n",
       "0              103             16.62                254.4                103   \n",
       "1              110             10.30                162.6                104   \n",
       "2               88              5.26                196.9                 89   \n",
       "3              122             12.61                186.9                121   \n",
       "4              108             29.62                212.6                118   \n",
       "\n",
       "   total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
       "0               11.45                13.7                 3   \n",
       "1                7.32                12.2                 5   \n",
       "2                8.86                 6.6                 7   \n",
       "3                8.41                10.1                 3   \n",
       "4                9.57                 7.5                 7   \n",
       "\n",
       "   total_intl_charge  number_customer_service_calls  churn  \\\n",
       "0               3.70                              1      0   \n",
       "1               3.29                              0      0   \n",
       "2               1.78                              2      0   \n",
       "3               2.73                              3      0   \n",
       "4               2.03                              3      0   \n",
       "\n",
       "   area_code_area_code_415  area_code_area_code_510  \n",
       "0                        1                        0  \n",
       "1                        1                        0  \n",
       "2                        0                        0  \n",
       "3                        1                        0  \n",
       "4                        0                        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define target variable (churn) and other binary variables as 0-1\n",
    "data = data.replace({'churn': {'yes': 1, 'no': 0}, \n",
    "                    'international_plan': {'yes': 1, 'no': 0}, \n",
    "                    'voice_mail_plan': {'yes': 1, 'no': 0}})\n",
    "\n",
    "# Define area_code dummy\n",
    "data = pd.get_dummies(data, columns = ['area_code'], drop_first=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot target variable --> we have an imbalanced class\n",
    "plt.pie(data[\"churn\"].value_counts(), autopct = '%.1f%%')\n",
    "plt.legend([\"Churn = no\", \"Churn = yes\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86470588 0.85294118 0.87058824 0.83823529 0.85882353 0.85294118\n",
      " 0.85882353 0.86470588 0.87941176 0.86764706]\n",
      "Average Accuracy score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Split to create a final evaluation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\"churn\", axis=1), data[\"churn\"], test_size=0.2, random_state=123)\n",
    "\n",
    "# Scale the dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train))  # store in dataframe for stratified kfold later\n",
    "X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "# Cross validation (example only on Logistic Regression)\n",
    "lr = LogisticRegression()\n",
    "cvs_all = cross_validate(lr, X=X_train, y=y_train, cv=10, scoring=['accuracy'])\n",
    "cvs = cvs_all['test_accuracy']\n",
    "print(cvs)\n",
    "print(f\"Average Accuracy score: {round(np.mean(cvs), 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified kfoldVC score: 0.865\n",
      "Stratified kfoldVC score: 0.853\n",
      "Stratified kfoldVC score: 0.871\n",
      "Stratified kfoldVC score: 0.838\n",
      "Stratified kfoldVC score: 0.859\n",
      "Stratified kfoldVC score: 0.853\n",
      "Stratified kfoldVC score: 0.859\n",
      "Stratified kfoldVC score: 0.865\n",
      "Stratified kfoldVC score: 0.879\n",
      "Stratified kfoldVC score: 0.868\n",
      "Average Accuracy score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# stratified kfoldCV = the folds are made by preserving the percentage of samples for each class\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):   # train_index and test_index are arrays of indexes to select train and test folds \n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_cv, y_train_cv)\n",
    "    sc = lr.score(X_test_cv, y_test_cv)\n",
    "    print(f\"Stratified kfoldVC score: {round(sc, 3)}\")\n",
    "    scores.append(sc)\n",
    "\n",
    "print(f\"Average Accuracy score: {round(np.mean(scores), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on the final evaluation set \n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "final_acc = lr.score(X_test, y_test)\n",
    "print(round(final_acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoint classified as 1 (churn=yes) by our model = 25, pct = 2.941176470588235\n",
      "Number of datapoints classified as 1 in the final evaluation set = 108, pct = 12.705882352941176\n",
      "--------------- Classification report ---------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94       742\n",
      "           1       0.80      0.19      0.30       108\n",
      "\n",
      "    accuracy                           0.89       850\n",
      "   macro avg       0.85      0.59      0.62       850\n",
      "weighted avg       0.88      0.89      0.86       850\n",
      "\n",
      "Accuracy is high but misleading, Recall is extremely low for class 1\n"
     ]
    }
   ],
   "source": [
    "# Problems with imbalanced class\n",
    "pred = lr.predict(X_test)\n",
    "print(f\"Number of datapoint classified as 1 (churn=yes) by our model = {sum(pred)}, pct = {sum(pred)/len(pred)*100}\")\n",
    "print(f\"Number of datapoints classified as 1 in the final evaluation set = {sum(y_test)}, pct = {sum(y_test)/len(y_test)*100}\")\n",
    "print(\"--------------- Classification report ---------------\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"Accuracy is high but misleading, Recall is extremely low for class 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Handle imbalanced class\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\"churn\", axis=1), data[\"churn\"], test_size=0.2, random_state=123)\n",
    "dt = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
    "\n",
    "# Use basic Over Sampling Minority Class resample method, (only training set) --> reference: (https://towardsdatascience.com/heres-what-i-ve-learnt-about-sklearn-resample-ab735ae1abc4)\n",
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "# set the minority class to a seperate dataframe\n",
    "dt_1 = dt[dt['churn'] == 1]\n",
    "# set other classes to another dataframe\n",
    "dt_0 = dt[dt['churn'] == 0]  \n",
    "# over-sample the minority class (5x)\n",
    "dt_1_oversampled = resample(dt_1, random_state=42, n_samples=len(dt_1)*5, replace=True)\n",
    "# concatenate the over-sample dataframe with the other\n",
    "dt_train_balanced = shuffle(pd.concat([dt_1_oversampled, dt_0]))\n",
    "\n",
    "# define X and y\n",
    "X_train_bal = dt_train_balanced.drop(\"churn\", axis=1)\n",
    "y_train_bal = dt_train_balanced[\"churn\"]\n",
    "\n",
    "plt.pie(dt_train_balanced['churn'].value_counts(), autopct = '%.1f%%')\n",
    "plt.legend([\"Churn = no\", \"Churn = yes\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy score LogReg: 0.78\n",
      "Average Accuracy score kNN: 0.85\n",
      "Evaluation set Accuracy LogReg: 0.8\n",
      "Evaluation set Accuracy kNN: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Repeat the same process as before with balanced training set\n",
    "# Scale\n",
    "scaler = MinMaxScaler()\n",
    "X_train_bal_sc = pd.DataFrame(scaler.fit_transform(X_train_bal)) \n",
    "X_test_sc = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "# Stratified kFold\n",
    "skf = StratifiedKFold(n_splits=6)\n",
    "\n",
    "scores_lr = []\n",
    "scores_knn = []\n",
    "scores_tr = []\n",
    "for train_index, test_index in skf.split(X_train_bal_sc, y_train_bal):   \n",
    "    X_train_cv, X_test_cv = X_train_bal_sc.iloc[train_index], X_train_bal_sc.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y_train_bal.iloc[train_index], y_train_bal.iloc[test_index]\n",
    "    lr = LogisticRegression()\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)\n",
    "    lr.fit(X_train_cv, y_train_cv)\n",
    "    knn.fit(X_train_cv, y_train_cv)\n",
    "    # Accuracy now should provide better info on the performance\n",
    "    sc_lr = lr.score(X_test_cv, y_test_cv)\n",
    "    sc_knn = knn.score(X_test_cv, y_test_cv)\n",
    "    scores_lr.append(sc_lr)\n",
    "    scores_knn.append(sc_knn)\n",
    "\n",
    "print(f\"Average Accuracy score LogReg: {round(np.mean(scores_lr), 2)}\")\n",
    "print(f\"Average Accuracy score kNN: {round(np.mean(scores_knn), 2)}\")\n",
    "\n",
    "# Final evaluation\n",
    "lr = LogisticRegression().fit(X_train_bal_sc, y_train_bal)\n",
    "knn = KNeighborsClassifier(n_neighbors=10).fit(X_train_bal_sc, y_train_bal)\n",
    "sc_lr = lr.score(X_test_sc, y_test)\n",
    "sc_knn = knn.score(X_test_sc, y_test)\n",
    "\n",
    "print(f\"Evaluation set Accuracy LogReg: {round(np.mean(sc_lr), 2)}\")\n",
    "print(f\"Evaluation set Accuracy kNN: {round(np.mean(sc_knn), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.88       742\n",
      "           1       0.36      0.72      0.48       108\n",
      "\n",
      "    accuracy                           0.80       850\n",
      "   macro avg       0.66      0.77      0.68       850\n",
      "weighted avg       0.88      0.80      0.83       850\n",
      "\n",
      "kNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       742\n",
      "           1       0.45      0.76      0.56       108\n",
      "\n",
      "    accuracy                           0.85       850\n",
      "   macro avg       0.70      0.81      0.74       850\n",
      "weighted avg       0.90      0.85      0.87       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_test_sc)\n",
    "print(\"LogReg\")\n",
    "print(classification_report(y_test, pred_lr))\n",
    "pred_knn = knn.predict(X_test_sc)\n",
    "print(\"kNN\")\n",
    "print(classification_report(y_test, pred_knn))\n",
    "# Now recall results are better (but still precision problems for class 1, etc....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1) Write __my_cross_validation_score__ function\n",
    "2) Perform Cross-validation (model selection) + Hold out (model evaluation) to select and evaluate the best model between a selection of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use titanic data to test my functions for simplicity (not very imbalanced)\n",
    "df_tita = pd.read_csv('data/titanic.csv')   # modify path if needed\n",
    "df_tita = df_tita[['Pclass', 'SibSp', 'Parch', 'Fare', \"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(df, target_col=None, random_shuffle=True, train_size=0.8, random_state=True, separated=True):\n",
    "    \"\"\"\n",
    "    Split a dataframe in train and test sets\n",
    "    PARAMETERS: \n",
    "    - df = pandas dataframes with X and y\n",
    "    - target_col = string, name of the y column\n",
    "    - random_shuffle = boolean, (default True), if True shuffle the dataset before splitting (False can be used for example for autocorrelated data)\n",
    "    - train_size = float, percentage of datapoints to be used as train set\n",
    "    - random_state = boolean, (default True), if True the results are fixed for each re-run, random otherwise\n",
    "    - separated = boolean, (default True), if True the function returns X_train, X_test, y_train, y_test, otherwise it returns train, test\n",
    "    OUTPUT: X_train, X_test, y_train, y_test or train, test\n",
    "    \"\"\"\n",
    "    n = int(len(df)*train_size)\n",
    "    if random_shuffle == True: \n",
    "        if random_state == True: df_s = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "        else: df_s = df.sample(frac=1).reset_index(drop=True)\n",
    "    else: df_s = df\n",
    "    if separated == True:\n",
    "        X_train = pd.DataFrame(df_s.drop(target_col, axis=1).loc[:n, :])\n",
    "        y_train = pd.DataFrame(df_s.loc[:n, target_col])\n",
    "        X_test = pd.DataFrame(df_s.drop(target_col, axis=1).loc[n+1:, :])\n",
    "        y_test = pd.DataFrame(df_s.loc[n+1:, target_col])\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        train = pd.DataFrame(df_s.loc[:n, :])\n",
    "        test = pd.DataFrame(df_s.loc[n+1:, :])\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = my_train_test_split(df_tita, \"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "891\n"
     ]
    }
   ],
   "source": [
    "print(len(df_tita))\n",
    "print(len(X_train)+len(X_test))  # ok, same lenght as original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_nblocks(df, n_blocks=5):\n",
    "    \"\"\"\n",
    "    Split a dataframe into n separate blocks, no random shuffle\n",
    "    PARAMETERS:\n",
    "    - df = pandas dataframe\n",
    "    - n_blocks = number of sub-dataframes wanted\n",
    "    OUTPUT: list of sub-dataframes\n",
    "    \"\"\"\n",
    "    block_len = int(len(df)/n_blocks)\n",
    "    blocks = [df[(i*block_len):((i+1)*(block_len))][:] for i in range(n_blocks)]\n",
    "    return blocks # list of df, few datapoints might get lost\n",
    "\n",
    "df1, df2, df3 = [split_df_nblocks(df_tita, n_blocks=3)[i] for i in range(3)]   #ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_validation_score(model, df, target_col=None, k=5, eval_score=\"accuracy\", random_state=True, debug=False):\n",
    "    \"\"\"\n",
    "    Compute cross validations score for each block and final score, std dev of scores (unable to handle umbalanced datasets as in this case, 'stratified' option could be added)\n",
    "    PARAMETERS:\n",
    "    - model = sklearn model object (for example KNeighborsClassifier())\n",
    "    - df = pandas dataframe with both X and y variables to be used in the model\n",
    "    - target_col = string, column name to identify y column (class to predict)\n",
    "    - k = int, number of cross validation blocks\n",
    "    - eval_score = string, performance metric used to evaluate the model, options are \"accuracy\" or \"auc\"\n",
    "    - random_state = bool, if True the results don't change after re-run\n",
    "    - debug = bool, if True print some info\n",
    "    OUTPUT: average score (float), standard deviation of scores (float), list of score for each block\n",
    "    \"\"\"\n",
    "    if random_state == True: df_s = df.sample(frac=1, random_state=123)\n",
    "    else: df_s = df.sample(frac=1)\n",
    "    list_blocks = split_df_nblocks(df_s, n_blocks=k)\n",
    "    if debug == True:\n",
    "        print(f\"Number of blocks created: {len(list_blocks)}\")\n",
    "        print(f\"Lenght of the first block: {len(list_blocks[0])}\")\n",
    "        print(f\"Lenght of the last block: {len(list_blocks[-1])}\")\n",
    "        print(f\"Datapoints lost: {(len(df)-len(list_blocks[0])*k)}\")\n",
    "    cv_scores = []\n",
    "    for i, block in enumerate(list_blocks):\n",
    "        if debug == True: print(f\"Test set is block number {i+1}\")\n",
    "        # select all df in the list expect one and concatenate them to get training dataset\n",
    "        train = pd.concat([bl for j, bl in enumerate(list_blocks) if j != i])\n",
    "        if debug == True: print(f\"Lenght of training set: {len(train)}\")\n",
    "        X_tr = train.drop(target_col, axis=1)\n",
    "        y_tr = train[target_col]\n",
    "        # use selected dataframe (block) as test set\n",
    "        X_test = block.drop(target_col, axis=1)\n",
    "        y_test = block[target_col]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        if eval_score == \"accuracy\": \n",
    "            sc = model.score(X_test, y_test)\n",
    "            cv_scores.append(sc)\n",
    "        elif eval_score == \"auc\": \n",
    "            probs = model.predict_proba(X_test) \n",
    "            probs1 = [j for i, j in probs]\n",
    "            fpr, tpr, _ = roc_curve(y_test, probs1)\n",
    "            sc = auc(fpr, tpr)\n",
    "            cv_scores.append(sc)\n",
    "        # can add other performance metrics\n",
    "    avg_score = np.mean(cv_scores)\n",
    "    std_score = np.std(cv_scores)\n",
    "    return avg_score, std_score, cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.021731</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054164</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065388</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp     Parch      Fare  Survived\n",
       "0     1.0  0.125  0.166667  0.021731       1.0\n",
       "1     1.0  0.000  0.000000  0.014110       0.0\n",
       "2     0.0  0.000  0.000000  0.054164       0.0\n",
       "3     0.0  0.000  0.000000  0.065388       0.0\n",
       "4     1.0  0.125  0.000000  0.028213       0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split\n",
    "data_train, data_test = my_train_test_split(df_tita, separated=False)\n",
    "\n",
    "# Example scale the data (scaling can be used without problems in my functions)\n",
    "scaler = MinMaxScaler()\n",
    "data_train_sc = pd.DataFrame(scaler.fit_transform(data_train), columns=data_train.columns) \n",
    "data_test_sc = pd.DataFrame(scaler.transform(data_test), columns=data_test.columns)\n",
    "data_train_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks created: 4\n",
      "Lenght of the first block: 178\n",
      "Lenght of the last block: 178\n",
      "Datapoints lost: 1\n",
      "Test set is block number 1\n",
      "Lenght of training set: 534\n",
      "Test set is block number 2\n",
      "Lenght of training set: 534\n",
      "Test set is block number 3\n",
      "Lenght of training set: 534\n",
      "Test set is block number 4\n",
      "Lenght of training set: 534\n"
     ]
    }
   ],
   "source": [
    "# Check if the function is working correctly\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "_, _, _ = my_cross_validation_score(knn, data_train_sc, target_col=\"Survived\", k=4, debug=True)  # use only training set\n",
    "\n",
    "# Ok number of blocks, ok lenght is the same for each one, \n",
    "# Ok in the loop each time all the remaining blocks are combined to create the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.702247191011236, 0.6966292134831461, 0.6404494382022472, 0.7078651685393258]\n",
      "0.687\n"
     ]
    }
   ],
   "source": [
    "# Function output\n",
    "avg_score, std_score, list_scores = my_cross_validation_score(knn, data_train_sc, target_col=\"Survived\", k=4)\n",
    "print(list_scores)\n",
    "print(round(avg_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_selection_evaluation(dict_models, trtestcv, final_test, target_col=None, k=5, eval_score=\"accuracy\", eval_all=False, random_state=True, debug=False):\n",
    "    \"\"\"\n",
    "    Perform cross-validation for all the models passed, select the best performer and test it on a final evaluation set. \n",
    "    PARAMETERS:\n",
    "    - dict_models = dictionary, all the models to test (for example dict_model = {\"KNN\": KNeighborsClassifier(), \"Logreg\": LogisticRegression()}) \n",
    "    - trtestcv = dataframe to be used in the cross-validation process\n",
    "    - final_test = dataframe to be used in the final evaluation process\n",
    "    - eval_all = bool, if True add to the final dataframe the performance on the final evaluation set for all the models\n",
    "    - target_col, k, eval_score, random_state, debug ===> same as the function 'my_cross_validation_score'\n",
    "    OUTPUT: pandas dataframe with results of model selection, name and score for the best performer, fitted model object for the best performer\n",
    "    \"\"\"\n",
    "    # 1) Define final evaluation set\n",
    "    if debug == True: print(f\"Lenght of final evaluation set: {len(final_test)}\")\n",
    "    X_finaltest = final_test.drop(target_col, axis=1)\n",
    "    y_finaltest = final_test[target_col]\n",
    "    # 2) perform kfoldCV for each model in the dictionary\n",
    "    cv_eval_results = pd.DataFrame(index = list(dict_models.keys()), columns=[f\"Block {i+1}\" for i in range(k)])\n",
    "    for name, mod in dict_models.items():\n",
    "        # pass only the df part selected to be used in the CV process (trtestcv)\n",
    "        avg_sc, stdev_sc, list_scores = my_cross_validation_score(mod, df=trtestcv, target_col=target_col, k=k, eval_score=eval_score, random_state=random_state)\n",
    "        # list(dict_models.keys()).index(name) used to avoid warning future error with loc\n",
    "        cv_eval_results.iloc[list(dict_models.keys()).index(name), :k] = list_scores\n",
    "        cv_eval_results.loc[name, \"Average_Score\"] = avg_sc\n",
    "        cv_eval_results.loc[name, \"StdDev_Score\"] = stdev_sc\n",
    "        if debug == True: print(f\"Evaluating {name} --> kfoldCV score = {round(avg_sc, 3)}\")\n",
    "        # 2.1) Compute performance on final_test set for all models if parameter is True\n",
    "        mod.fit(trtestcv.drop(target_col, axis=1), trtestcv[target_col])\n",
    "        if eval_all == True:\n",
    "            if eval_score == \"accuracy\": \n",
    "                final_score = mod.score(X_finaltest, y_finaltest)\n",
    "                cv_eval_results.loc[name, \"Score_final_evaluation\"] = final_score\n",
    "                if debug == True: print(f\"Computing score on final evaluation set for {name} --> score = {round(final_score, 3)}\")\n",
    "            elif eval_score == \"auc\": \n",
    "                probs = mod.predict_proba(X_finaltest) \n",
    "                probs1 = [j for i, j in probs]\n",
    "                fpr, tpr, _ = roc_curve(y_finaltest, probs1)\n",
    "                final_score = auc(fpr, tpr)\n",
    "                cv_eval_results.loc[name, \"Score_final_evaluation\"] = final_score\n",
    "                if debug == True: print(f\"Computing score on final evaluation for {name} --> score = {round(final_score, 3)}\")\n",
    "    # 3) Select best performer and evaluate it on the final evaluation set\n",
    "    best_model = cv_eval_results[\"Average_Score\"].idxmax()\n",
    "    if debug == True: print(f\"The best model is {best_model}\")\n",
    "    bestmod = dict_models[best_model]\n",
    "    # use the entire dataset used for kfoldCV as training set\n",
    "    bestmod.fit(trtestcv.drop(target_col, axis=1), trtestcv[target_col])\n",
    "    if eval_score == \"accuracy\": \n",
    "        final_score_best = bestmod.score(X_finaltest, y_finaltest)\n",
    "    elif eval_score == \"auc\": \n",
    "        probs = bestmod.predict_proba(X_finaltest) \n",
    "        probs1 = [j for i, j in probs]\n",
    "        fpr, tpr, _ = roc_curve(y_finaltest, probs1)\n",
    "        final_score_best = auc(fpr, tpr)\n",
    "    return cv_eval_results, best_model, final_score_best, bestmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of final evaluation set: 178\n",
      "Evaluating kNN_5 --> kfoldCV score = 0.681\n",
      "Computing score on final evaluation set for kNN_5 --> score = 0.663\n",
      "Evaluating kNN_20 --> kfoldCV score = 0.692\n",
      "Computing score on final evaluation set for kNN_20 --> score = 0.708\n",
      "Evaluating LogReg --> kfoldCV score = 0.698\n",
      "Computing score on final evaluation set for LogReg --> score = 0.635\n",
      "Evaluating DecisionTree --> kfoldCV score = 0.688\n",
      "Computing score on final evaluation set for DecisionTree --> score = 0.674\n",
      "The best model is LogReg\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "models = {\"kNN_5\": KNeighborsClassifier(n_neighbors=5), \n",
    "        \"kNN_20\": KNeighborsClassifier(n_neighbors=20), \n",
    "        \"LogReg\": LogisticRegression(),\n",
    "        \"DecisionTree\": DecisionTreeClassifier()}\n",
    "\n",
    "df_sel, best, final_sc_best, best_fitted = models_selection_evaluation(dict_models=models,  # all models to be tested\n",
    "                                                        trtestcv=data_train_sc, final_test=data_test_sc,  # datasets\n",
    "                                                        target_col=\"Survived\", k=3, eval_all = True,\n",
    "                                                        debug=True, )\n",
    "# test seems ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Block 1</th>\n",
       "      <th>Block 2</th>\n",
       "      <th>Block 3</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>StdDev_Score</th>\n",
       "      <th>Score_final_evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kNN_5</th>\n",
       "      <td>0.679325</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.680731</td>\n",
       "      <td>0.012099</td>\n",
       "      <td>0.662921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN_20</th>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.700422</td>\n",
       "      <td>0.691983</td>\n",
       "      <td>0.024843</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.704641</td>\n",
       "      <td>0.704641</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.697609</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>0.634831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.687764</td>\n",
       "      <td>0.687764</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>0.674157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Block 1   Block 2   Block 3  Average_Score  StdDev_Score  \\\n",
       "kNN_5         0.679325  0.666667  0.696203       0.680731      0.012099   \n",
       "kNN_20          0.7173  0.658228  0.700422       0.691983      0.024843   \n",
       "LogReg        0.704641  0.704641  0.683544       0.697609      0.009945   \n",
       "DecisionTree  0.708861  0.666667  0.687764       0.687764      0.017226   \n",
       "\n",
       "              Score_final_evaluation  \n",
       "kNN_5                       0.662921  \n",
       "kNN_20                      0.707865  \n",
       "LogReg                      0.634831  \n",
       "DecisionTree                0.674157  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with the Cross Validation model selection results \n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LogReg', 0.635)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best performing model and its score on the final evaluation set\n",
    "# obvously automatic selection of the best performer is not always the best solution\n",
    "# implemented just as an exercise\n",
    "best, round(final_sc_best, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.85      0.72        97\n",
      "         1.0       0.67      0.38      0.49        81\n",
      "\n",
      "    accuracy                           0.63       178\n",
      "   macro avg       0.65      0.61      0.60       178\n",
      "weighted avg       0.65      0.63      0.61       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform other operations on the best model\n",
    "best_pred = best_fitted.predict(data_test_sc.drop(\"Survived\", axis=1))\n",
    "print(classification_report(data_test_sc[\"Survived\"], best_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecdf108b986fec06f7876a2b77fffab883fa2c721c4866b9970845870539861b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
