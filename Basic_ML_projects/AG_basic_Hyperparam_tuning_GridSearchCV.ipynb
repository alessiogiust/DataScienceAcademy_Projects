{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[['Pclass', 'SibSp', 'Parch', 'Fare']]\n",
    "Y_train = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=50, weights='distance')\n",
      "{'n_neighbors': 50, 'weights': 'distance'}\n",
      "\n",
      "\n",
      "------------ All parameter combinations tested ------------\n",
      "[{'n_neighbors': 5, 'weights': 'uniform'}, {'n_neighbors': 5, 'weights': 'distance'}, {'n_neighbors': 20, 'weights': 'uniform'}, {'n_neighbors': 20, 'weights': 'distance'}, {'n_neighbors': 50, 'weights': 'uniform'}, {'n_neighbors': 50, 'weights': 'distance'}]\n",
      "\n",
      "\n",
      "------------ Results for each combination (6) given split 1 ------------\n",
      "[0.67977528 0.66853933 0.69662921 0.71348315 0.69662921 0.71348315]\n",
      "\n",
      "\n",
      "------------ Average result for each combination ------------\n",
      "------------ (mean of score for all combinations over each split) ------------\n",
      "[0.67113803 0.66552633 0.68240537 0.68464629 0.67791099 0.68576361]\n",
      "\n",
      "\n",
      "We can see that the 6-th combination is the best because the highest accuracy is the last element of the mean_test_score array\n"
     ]
    }
   ],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"n_neighbors\": [5,20,50],\n",
    "        \"weights\": ['uniform', 'distance']}   # 6 total combinations\n",
    "\n",
    "# Define two stratkfoldCV splits\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Define target model and tune hyperparam\n",
    "knn = KNeighborsClassifier()\n",
    "clf = GridSearchCV(estimator=knn, param_grid=p_grid, cv=inner_cv)   # grid search CV setup\n",
    "# find best hyperparam for kNN using inner_cv (5 splits)\n",
    "gscv = clf.fit(X_train, Y_train)\n",
    "print(gscv.best_estimator_)\n",
    "print(gscv.best_params_)\n",
    "print('\\n')\n",
    "print(\"------------ All parameter combinations tested ------------\")\n",
    "print(gscv.cv_results_['params'])\n",
    "print('\\n')\n",
    "print(\"------------ Results for each combination (6) given split 1 ------------\")\n",
    "print(gscv.cv_results_['split1_test_score'])\n",
    "print('\\n')\n",
    "print(\"------------ Average result for each combination ------------\")\n",
    "print(\"------------ (mean of score for all combinations over each split) ------------\")\n",
    "print(gscv.cv_results_['mean_test_score'])\n",
    "print('\\n')\n",
    "print(\"We can see that the 6-th combination is the best because the highest accuracy is the last element of the mean_test_score array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.9793618166780922, 'fit_intercept': True, 'penalty': 'l2'}\n",
      "\n",
      "\n",
      "          C  fit_intercept penalty  mean_test_score\n",
      "0  0.763540          False      l2         0.674559\n",
      "1  1.979362           True      l2         0.683542\n",
      "2  2.247328          False      l2         0.674559\n",
      "3  0.966326          False      l2         0.674559\n",
      "4  2.086444           True      l2         0.683542\n",
      "5  2.529099          False      l2         0.674559\n",
      "6  1.210238           True      l2         0.683542\n",
      "7  2.514719           True      l2         0.683542\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "p_distrib = {'C': uniform(loc=0, scale=3),\n",
    "            'penalty': ['l2'], \n",
    "            'fit_intercept': [True, False]}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator=logistic, \n",
    "                        param_distributions=p_distrib, # parameters options and/or distributions\n",
    "                        cv=inner_cv, # cv splits to use\n",
    "                        n_iter=8)   # number of random parameters combinations\n",
    "# find best hyperparam for kNN using inner_cv (5 splits)\n",
    "Rgscv = clf.fit(X_train, Y_train)\n",
    "df = pd.DataFrame(Rgscv.cv_results_)\n",
    "df1 = df[\"params\"].apply(pd.Series)\n",
    "df = pd.merge(df.drop(\"params\", axis=1), df1, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "print(f\"Best parameters: {Rgscv.best_params_}\")\n",
    "print(\"\\n\")\n",
    "print(df[['C', 'fit_intercept', 'penalty', 'mean_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only hyperparameters tuning: final score for best combination of param = 0.683541522817149\n",
      "Nested CV: final score for best combination of param = 0.693567446370137\n"
     ]
    }
   ],
   "source": [
    "# DOCS EXAMPLE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=123)\n",
    "\n",
    "# Non_nested parameter search and scoring (only hyper tuning)\n",
    "clf1 = GridSearchCV(estimator=svm, param_grid=p_grid, cv=outer_cv) \n",
    "clf1.fit(X_train, Y_train)\n",
    "non_nested_score = clf.best_score_\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "clf2 = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)       # hyper tuning, score is the one used to select the best model\n",
    "nested_score = cross_val_score(clf2, X=X_train, y=Y_train, cv=outer_cv)  # CV score for the best combination, obtained from a different random split of the dataset\n",
    "nested_score = nested_score.mean()\n",
    "\n",
    "print(f\"Only hyperparameters tuning: final score for best combination of param = {non_nested_score}\")\n",
    "print(f\"Nested CV: final score for best combination of param = {nested_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
